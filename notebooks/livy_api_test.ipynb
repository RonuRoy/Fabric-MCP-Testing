{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86085889",
   "metadata": {},
   "source": [
    "# Microsoft Fabric Livy API Testing Notebook\n",
    "\n",
    "This notebook demonstrates how to use the Microsoft Fabric Livy API for interactive Spark sessions. It supports both bearer token authentication (for testing) and service principal authentication (for production scenarios).\n",
    "\n",
    "## Features\n",
    "- ‚úÖ Session management (create, monitor, delete)\n",
    "- ‚úÖ Statement execution with polling\n",
    "- ‚úÖ Multiple authentication methods\n",
    "- ‚úÖ Real-world examples with your workspace\n",
    "\n",
    "## Your Configuration\n",
    "- **Workspace ID**: `c22f6805-d84a-4143-80b2-0c9e9832e5a2`\n",
    "- **Lakehouse ID**: `683ce7d6-5d0d-4164-b594-d2cc8dbf70ac`\n",
    "- **Warehouse ID**: `f01cc17b-6db8-47eb-b3cb-d0b43b1ad8e8`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8b8d48",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import all necessary libraries for Livy API testing including authentication, HTTP requests, and JSON handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core libraries\n",
    "import requests\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from typing import Optional, Dict, Any\n",
    "\n",
    "# Authentication libraries (install if needed: pip install msal)\n",
    "try:\n",
    "    from msal import ConfidentialClientApplication, PublicClientApplication\n",
    "    MSAL_AVAILABLE = True\n",
    "    print(\"‚úÖ MSAL library is available for service principal authentication\")\n",
    "except ImportError:\n",
    "    MSAL_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è MSAL library not available. Only bearer token authentication will work.\")\n",
    "    print(\"   Install with: pip install msal\")\n",
    "\n",
    "print(\"üìö Libraries imported successfully!\")\n",
    "print(f\"üïê Current time: {datetime.now()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edffd9f",
   "metadata": {},
   "source": [
    "## 2. Set Configuration Parameters\n",
    "\n",
    "Configure your Microsoft Fabric workspace, lakehouse, and authentication credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81ef231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration - Update these with your specific values\n",
    "config = {\n",
    "    # Your specific Microsoft Fabric workspace and lakehouse IDs\n",
    "    \"workspace_id\": \"c22f6805-d84a-4143-80b2-0c9e9832e5a2\",\n",
    "    \"lakehouse_id\": \"683ce7d6-5d0d-4164-b594-d2cc8dbf70ac\", \n",
    "    \"warehouse_id\": \"f01cc17b-6db8-47eb-b3cb-d0b43b1ad8e8\",  # Optional for warehouse operations\n",
    "    \n",
    "    # Authentication settings\n",
    "    \"use_bearer_token\": True,  # Set to False to use service principal auth\n",
    "    \n",
    "    # Bearer Token Authentication (for local testing)\n",
    "    \"bearer_token\": \"\",  # Paste your bearer token here or leave empty to be prompted\n",
    "    \n",
    "    # Service Principal Authentication (for production)\n",
    "    \"tenant_id\": \"\",      # Your Azure AD tenant ID\n",
    "    \"client_id\": \"\",      # Your service principal client ID  \n",
    "    \"client_secret\": \"\",  # Your service principal client secret\n",
    "    \n",
    "    # API settings\n",
    "    \"fabric_base_url\": \"https://api.fabric.microsoft.com/v1\",\n",
    "    \"timeout_seconds\": 300,\n",
    "    \"max_poll_attempts\": 30\n",
    "}\n",
    "\n",
    "# Prompt for credentials if not provided\n",
    "if config[\"use_bearer_token\"]:\n",
    "    if not config[\"bearer_token\"]:\n",
    "        print(\"üîë Bearer Token Authentication\")\n",
    "        print(\"To get your bearer token:\")\n",
    "        print(\"1. Open Microsoft Fabric in your browser\")\n",
    "        print(\"2. Press F12 to open Developer Tools\")\n",
    "        print(\"3. Go to Network tab\")\n",
    "        print(\"4. Refresh the page\")\n",
    "        print(\"5. Look for any request and find 'Authorization: Bearer ...' in the headers\")\n",
    "        print(\"6. Copy the token (everything after 'Bearer ')\")\n",
    "        print()\n",
    "        config[\"bearer_token\"] = input(\"Paste your bearer token here: \").strip()\n",
    "        \n",
    "    if not config[\"bearer_token\"]:\n",
    "        raise ValueError(\"‚ùå Bearer token is required for authentication\")\n",
    "        \n",
    "    print(\"‚úÖ Using Bearer Token authentication\")\n",
    "else:\n",
    "    # Service Principal authentication\n",
    "    if not all([config[\"tenant_id\"], config[\"client_id\"], config[\"client_secret\"]]):\n",
    "        print(\"üîê Service Principal Authentication\")\n",
    "        print(\"Enter your Azure AD service principal credentials:\")\n",
    "        \n",
    "        if not config[\"tenant_id\"]:\n",
    "            config[\"tenant_id\"] = input(\"Tenant ID: \").strip()\n",
    "        if not config[\"client_id\"]:\n",
    "            config[\"client_id\"] = input(\"Client ID: \").strip()\n",
    "        if not config[\"client_secret\"]:\n",
    "            config[\"client_secret\"] = input(\"Client Secret: \").strip()\n",
    "    \n",
    "    if not all([config[\"tenant_id\"], config[\"client_id\"], config[\"client_secret\"]]):\n",
    "        raise ValueError(\"‚ùå Service principal credentials are required\")\n",
    "        \n",
    "    print(\"‚úÖ Using Service Principal authentication\")\n",
    "\n",
    "print(f\"\\nüìã Configuration Summary:\")\n",
    "print(f\"   Workspace ID: {config['workspace_id']}\")\n",
    "print(f\"   Lakehouse ID: {config['lakehouse_id']}\")\n",
    "print(f\"   Warehouse ID: {config['warehouse_id']}\")\n",
    "print(f\"   Auth Method: {'Bearer Token' if config['use_bearer_token'] else 'Service Principal'}\")\n",
    "print(f\"   Fabric API: {config['fabric_base_url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9820cc6",
   "metadata": {},
   "source": [
    "## 3. Authentication: Bearer Token or Service Principal\n",
    "\n",
    "Acquire an access token using either bearer token or service principal credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc57cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_service_principal_token(tenant_id: str, client_id: str, client_secret: str) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Get an access token using service principal credentials.\n",
    "    \"\"\"\n",
    "    if not MSAL_AVAILABLE:\n",
    "        print(\"‚ùå MSAL library not available for service principal authentication\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        authority = f\"https://login.microsoftonline.com/{tenant_id}\"\n",
    "        audience = \"https://api.fabric.microsoft.com/.default\"\n",
    "        \n",
    "        app = ConfidentialClientApplication(\n",
    "            client_id=client_id,\n",
    "            client_credential=client_secret,\n",
    "            authority=authority\n",
    "        )\n",
    "        \n",
    "        result = app.acquire_token_for_client(scopes=[audience])\n",
    "        \n",
    "        if \"access_token\" in result:\n",
    "            print(\"‚úÖ Service principal authentication successful\")\n",
    "            return result[\"access_token\"]\n",
    "        else:\n",
    "            error_desc = result.get('error_description', 'Unknown error')\n",
    "            print(f\"‚ùå Service principal authentication failed: {error_desc}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during service principal authentication: {e}\")\n",
    "        return None\n",
    "\n",
    "# Authentication\n",
    "print(\"üîê Authenticating with Microsoft Fabric...\")\n",
    "\n",
    "access_token = None\n",
    "\n",
    "if config[\"use_bearer_token\"]:\n",
    "    # Use provided bearer token directly\n",
    "    access_token = config[\"bearer_token\"]\n",
    "    print(\"‚úÖ Using provided bearer token\")\n",
    "    \n",
    "else:\n",
    "    # Service Principal authentication using MSAL\n",
    "    print(\"üîÑ Getting access token using service principal...\")\n",
    "    \n",
    "    try:\n",
    "        from msal import ConfidentialClientApplication\n",
    "        \n",
    "        # Create authority URL\n",
    "        authority = f\"https://login.microsoftonline.com/{config['tenant_id']}\"\n",
    "        \n",
    "        # Create MSAL app\n",
    "        app = ConfidentialClientApplication(\n",
    "            client_id=config[\"client_id\"],\n",
    "            client_credential=config[\"client_secret\"],\n",
    "            authority=authority\n",
    "        )\n",
    "        \n",
    "        # Define scopes for Fabric API\n",
    "        scopes = [\"https://api.fabric.microsoft.com/.default\"]\n",
    "        \n",
    "        # Acquire token\n",
    "        result = app.acquire_token_for_client(scopes=scopes)\n",
    "        \n",
    "        if \"access_token\" in result:\n",
    "            access_token = result[\"access_token\"]\n",
    "            print(\"‚úÖ Successfully obtained access token via service principal\")\n",
    "        else:\n",
    "            error_desc = result.get(\"error_description\", \"Unknown error\")\n",
    "            raise Exception(f\"Failed to get access token: {error_desc}\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"‚ùå MSAL library not found. Install it with: pip install msal\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Service principal authentication failed: {e}\")\n",
    "        raise\n",
    "\n",
    "if not access_token:\n",
    "    raise ValueError(\"‚ùå Failed to obtain access token\")\n",
    "\n",
    "# Set up request headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {access_token}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Authentication successful!\")\n",
    "print(f\"üìä Token length: {len(access_token)} characters\")\n",
    "print(f\"üîë Token prefix: {access_token[:20]}...\" if len(access_token) > 20 else \"üîë Token obtained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc87bb",
   "metadata": {},
   "source": [
    "## 4. Build Livy API Endpoints\n",
    "\n",
    "Construct the Livy session and batch endpoints using your workspace and lakehouse IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22708b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Livy API endpoints\n",
    "print(\"üîó Building Livy API endpoints...\")\n",
    "\n",
    "# Base URL using msitapi.fabric.microsoft.com as per your specification\n",
    "livy_base_url = f\"https://msitapi.fabric.microsoft.com/v1/workspaces/{config['workspace_id']}/lakehouses/{config['lakehouse_id']}/livyapi/versions/2023-12-01\"\n",
    "\n",
    "# Session endpoints\n",
    "session_endpoints = {\n",
    "    \"sessions\": f\"{livy_base_url}/sessions\",\n",
    "    \"session_detail\": f\"{livy_base_url}/sessions/{{session_id}}\",\n",
    "    \"statements\": f\"{livy_base_url}/sessions/{{session_id}}/statements\",\n",
    "    \"statement_detail\": f\"{livy_base_url}/sessions/{{session_id}}/statements/{{statement_id}}\"\n",
    "}\n",
    "\n",
    "# Batch endpoints  \n",
    "batch_endpoints = {\n",
    "    \"batches\": f\"{livy_base_url}/batches\",\n",
    "    \"batch_detail\": f\"{livy_base_url}/batches/{{batch_id}}\"\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Livy API endpoints configured:\")\n",
    "print(f\"   Sessions URL: {session_endpoints['sessions']}\")\n",
    "print(f\"   Batches URL: {batch_endpoints['batches']}\")\n",
    "print(f\"   API Version: 2023-12-01\")\n",
    "print(f\"   Using msitapi.fabric.microsoft.com endpoint\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2473686e",
   "metadata": {},
   "source": [
    "## 5. Create Livy Session\n",
    "\n",
    "Create a new interactive Livy session for executing Spark code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178705d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Livy session\n",
    "print(f\"üöÄ Creating Livy session at {datetime.now()}\")\n",
    "print(f\"üì° POST {sessions_url}\")\n",
    "\n",
    "session_config = {\n",
    "    \"kind\": \"spark\",\n",
    "    \"name\": f\"test-session-{int(time.time())}\"\n",
    "}\n",
    "\n",
    "try:\n",
    "    create_session_response = requests.post(sessions_url, headers=headers, json=session_config)\n",
    "    \n",
    "    print(f\"üì• Response Status: {create_session_response.status_code}\")\n",
    "    \n",
    "    if create_session_response.status_code == 201:\n",
    "        session_data = create_session_response.json()\n",
    "        livy_session_id = session_data['id']\n",
    "        session_state = session_data.get('state', 'unknown')\n",
    "        session_kind = session_data.get('kind', 'unknown')\n",
    "        \n",
    "        print(f\"‚úÖ Livy session created successfully!\")\n",
    "        print(f\"üÜî Session ID: {livy_session_id}\")\n",
    "        print(f\"üéØ State: {session_state}\")\n",
    "        print(f\"üè∑Ô∏è Kind: {session_kind}\")\n",
    "        print()\n",
    "        print(\"üìÑ Full session response:\")\n",
    "        print(json.dumps(session_data, indent=2))\n",
    "        \n",
    "        # Build session-specific URL\n",
    "        livy_session_url = f\"{sessions_url}/{livy_session_id}\"\n",
    "        print(f\"üîó Session URL: {livy_session_url}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Failed to create session\")\n",
    "        print(f\"üìÑ Response: {create_session_response.text}\")\n",
    "        raise Exception(\"Session creation failed\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating session: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695fbcd7",
   "metadata": {},
   "source": [
    "## 6. Wait for Session to Become Idle\n",
    "\n",
    "Poll the session status until it's ready to accept statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51725d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for session to become idle\n",
    "print(f\"‚è≥ Waiting for session {livy_session_id} to become idle...\")\n",
    "max_wait_time = 300  # 5 minutes\n",
    "start_time = time.time()\n",
    "\n",
    "while time.time() - start_time < max_wait_time:\n",
    "    try:\n",
    "        get_session_response = requests.get(livy_session_url, headers=headers)\n",
    "        \n",
    "        if get_session_response.status_code == 200:\n",
    "            session_status = get_session_response.json()\n",
    "            current_state = session_status.get('state', 'unknown')\n",
    "            \n",
    "            print(f\"üìä Session {livy_session_id} state: {current_state} (elapsed: {int(time.time() - start_time)}s)\")\n",
    "            \n",
    "            if current_state == \"idle\":\n",
    "                print(f\"‚úÖ Session is ready!\")\n",
    "                break\n",
    "            elif current_state in [\"error\", \"dead\", \"killed\"]:\n",
    "                print(f\"‚ùå Session failed with state: {current_state}\")\n",
    "                print(json.dumps(session_status, indent=2))\n",
    "                raise Exception(f\"Session failed: {current_state}\")\n",
    "            else:\n",
    "                print(f\"‚è≥ Session still initializing... waiting 10 seconds\")\n",
    "                time.sleep(10)\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Error getting session status: {get_session_response.status_code}\")\n",
    "            time.sleep(10)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error checking session status: {e}\")\n",
    "        time.sleep(10)\n",
    "else:\n",
    "    print(f\"‚è∞ Timeout waiting for session to become idle\")\n",
    "    raise Exception(\"Session timeout\")\n",
    "\n",
    "print(f\"üéâ Session {livy_session_id} is ready for statements!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542927ca",
   "metadata": {},
   "source": [
    "## 7. Submit SQL Statement to Livy Session\n",
    "\n",
    "Now we'll submit a SQL statement to our active Livy session. We'll execute a simple query to test the connection to our lakehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c69614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit a SQL statement to the Livy session\n",
    "statement_payload = {\n",
    "    \"code\": \"SELECT 'Hello from Fabric Livy API!' as greeting, current_timestamp() as timestamp\",\n",
    "    \"kind\": \"sql\"\n",
    "}\n",
    "\n",
    "print(\"Submitting SQL statement to Livy session...\")\n",
    "statement_response = requests.post(\n",
    "    f\"{livy_base_url}/sessions/{session_id}/statements\",\n",
    "    headers=headers,\n",
    "    json=statement_payload\n",
    ")\n",
    "\n",
    "if statement_response.status_code == 201:\n",
    "    statement = statement_response.json()\n",
    "    statement_id = statement['id']\n",
    "    print(f\"‚úÖ Statement submitted successfully!\")\n",
    "    print(f\"üìã Statement ID: {statement_id}\")\n",
    "    print(f\"üîÑ Statement State: {statement['state']}\")\n",
    "else:\n",
    "    print(f\"‚ùå Failed to submit statement: {statement_response.status_code}\")\n",
    "    print(f\"Error: {statement_response.text}\")\n",
    "    statement_id = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b192d",
   "metadata": {},
   "source": [
    "## 8. Poll for Statement Result\n",
    "\n",
    "We'll poll the statement status until it's completed and then retrieve the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f68da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll for statement completion\n",
    "if statement_id is not None:\n",
    "    print(\"Polling for statement completion...\")\n",
    "    max_attempts = 30\n",
    "    attempt = 0\n",
    "    \n",
    "    while attempt < max_attempts:\n",
    "        statement_status_response = requests.get(\n",
    "            f\"{livy_base_url}/sessions/{session_id}/statements/{statement_id}\",\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if statement_status_response.status_code == 200:\n",
    "            statement_status = statement_status_response.json()\n",
    "            state = statement_status['state']\n",
    "            print(f\"üìä Attempt {attempt + 1}: Statement state is '{state}'\")\n",
    "            \n",
    "            if state == 'available':\n",
    "                print(\"‚úÖ Statement completed successfully!\")\n",
    "                \n",
    "                # Display the results\n",
    "                if 'output' in statement_status and statement_status['output']:\n",
    "                    output = statement_status['output']\n",
    "                    if output['status'] == 'ok':\n",
    "                        print(\"üìã Statement Results:\")\n",
    "                        if 'data' in output and 'text/plain' in output['data']:\n",
    "                            print(output['data']['text/plain'])\n",
    "                        else:\n",
    "                            print(\"No data returned\")\n",
    "                    else:\n",
    "                        print(f\"‚ùå Statement failed: {output.get('evalue', 'Unknown error')}\")\n",
    "                        if 'traceback' in output:\n",
    "                            print(\"Traceback:\")\n",
    "                            for line in output['traceback']:\n",
    "                                print(line)\n",
    "                break\n",
    "            elif state in ['error', 'cancelled', 'cancelling']:\n",
    "                print(f\"‚ùå Statement failed with state: {state}\")\n",
    "                if 'output' in statement_status:\n",
    "                    print(f\"Error: {statement_status['output']}\")\n",
    "                break\n",
    "            \n",
    "            time.sleep(2)\n",
    "            attempt += 1\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to get statement status: {statement_status_response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    if attempt >= max_attempts:\n",
    "        print(\"‚è∞ Timeout waiting for statement completion\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping statement polling - no statement ID available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5bb16b",
   "metadata": {},
   "source": [
    "## 9. Submit Additional SQL Statements\n",
    "\n",
    "Let's submit a few more SQL statements to demonstrate running multiple queries in the same session. These examples are based on your sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41dbd956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute and poll for statement results\n",
    "def execute_and_poll_statement(code, kind=\"sql\", description=\"\"):\n",
    "    \"\"\"Execute a statement and poll for results\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Executing: {description}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Wait for session to be idle first\n",
    "    print(\"Checking session state...\")\n",
    "    session_response = requests.get(f\"{livy_base_url}/sessions/{session_id}\", headers=headers)\n",
    "    if session_response.status_code == 200:\n",
    "        session_state = session_response.json()['state']\n",
    "        print(f\"Session state: {session_state}\")\n",
    "        \n",
    "        # Wait for idle state\n",
    "        while session_state != 'idle':\n",
    "            print(f\"Waiting for session to become idle (current: {session_state})...\")\n",
    "            time.sleep(5)\n",
    "            session_response = requests.get(f\"{livy_base_url}/sessions/{session_id}\", headers=headers)\n",
    "            if session_response.status_code == 200:\n",
    "                session_state = session_response.json()['state']\n",
    "            else:\n",
    "                print(f\"‚ùå Failed to get session status: {session_response.status_code}\")\n",
    "                return None\n",
    "    \n",
    "    # Submit statement\n",
    "    statement_payload = {\n",
    "        \"code\": code,\n",
    "        \"kind\": kind\n",
    "    }\n",
    "    \n",
    "    statement_response = requests.post(\n",
    "        f\"{livy_base_url}/sessions/{session_id}/statements\",\n",
    "        headers=headers,\n",
    "        json=statement_payload\n",
    "    )\n",
    "    \n",
    "    if statement_response.status_code != 201:\n",
    "        print(f\"‚ùå Failed to submit statement: {statement_response.status_code}\")\n",
    "        print(f\"Error: {statement_response.text}\")\n",
    "        return None\n",
    "    \n",
    "    statement_data = statement_response.json()\n",
    "    stmt_id = statement_data['id']\n",
    "    print(f\"‚úÖ Statement submitted with ID: {stmt_id}\")\n",
    "    \n",
    "    # Poll for completion\n",
    "    max_attempts = 30\n",
    "    attempt = 0\n",
    "    \n",
    "    while attempt < max_attempts:\n",
    "        statement_status_response = requests.get(\n",
    "            f\"{livy_base_url}/sessions/{session_id}/statements/{stmt_id}\",\n",
    "            headers=headers\n",
    "        )\n",
    "        \n",
    "        if statement_status_response.status_code == 200:\n",
    "            statement_status = statement_status_response.json()\n",
    "            state = statement_status['state']\n",
    "            \n",
    "            if state == 'available':\n",
    "                print(\"‚úÖ Statement completed!\")\n",
    "                if 'output' in statement_status and statement_status['output']:\n",
    "                    output = statement_status['output']\n",
    "                    if output['status'] == 'ok':\n",
    "                        if 'data' in output and 'text/plain' in output['data']:\n",
    "                            print(\"üìã Results:\")\n",
    "                            print(output['data']['text/plain'])\n",
    "                        else:\n",
    "                            print(\"‚úÖ Statement executed successfully (no data returned)\")\n",
    "                    else:\n",
    "                        print(f\"‚ùå Statement failed: {output.get('evalue', 'Unknown error')}\")\n",
    "                return statement_status\n",
    "            elif state in ['error', 'cancelled', 'cancelling']:\n",
    "                print(f\"‚ùå Statement failed with state: {state}\")\n",
    "                return statement_status\n",
    "            elif state in ['running', 'waiting']:\n",
    "                print(f\"üîÑ Statement {state}... (attempt {attempt + 1})\")\n",
    "            \n",
    "            time.sleep(3)\n",
    "            attempt += 1\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to get statement status: {statement_status_response.status_code}\")\n",
    "            break\n",
    "    \n",
    "    print(\"‚è∞ Timeout waiting for statement completion\")\n",
    "    return None\n",
    "\n",
    "# Example SQL statements to demonstrate the Livy API\n",
    "statements_to_execute = [\n",
    "    {\n",
    "        \"code\": \"SHOW TABLES\",\n",
    "        \"description\": \"List all tables in the lakehouse\"\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"SELECT 'Fabric Livy API Test' as message, current_timestamp() as execution_time\",\n",
    "        \"description\": \"Simple SELECT statement with timestamp\"\n",
    "    },\n",
    "    {\n",
    "        \"code\": \"SELECT 1 + 1 as calculation, 'Math works!' as message\",\n",
    "        \"description\": \"Basic calculation\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# Execute each statement\n",
    "for i, stmt in enumerate(statements_to_execute, 1):\n",
    "    print(f\"\\nüîÑ Executing Statement {i}/{len(statements_to_execute)}\")\n",
    "    result = execute_and_poll_statement(\n",
    "        stmt[\"code\"], \n",
    "        \"sql\", \n",
    "        stmt[\"description\"]\n",
    "    )\n",
    "    \n",
    "    if result is None:\n",
    "        print(f\"‚ö†Ô∏è Statement {i} failed or timed out\")\n",
    "    \n",
    "    # Small delay between statements\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e53970",
   "metadata": {},
   "source": [
    "## 10. Advanced Spark SQL Queries (Optional)\n",
    "\n",
    "If you have data tables in your lakehouse, you can uncomment and modify these examples to query your actual data. These are based on your sample queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6d052d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Spark SQL queries (uncomment and modify table names as needed)\n",
    "advanced_queries = [\n",
    "    {\n",
    "        \"code\": '''spark.sql(\"SHOW TABLES\").show()''',\n",
    "        \"kind\": \"spark\",\n",
    "        \"description\": \"Show all tables using Spark SQL\"\n",
    "    },\n",
    "    # Uncomment and modify these if you have the actual tables in your lakehouse\n",
    "    # {\n",
    "    #     \"code\": '''spark.sql(\"SELECT * FROM green_tripdata_2022_08 WHERE fare_amount = 60\").show()''',\n",
    "    #     \"kind\": \"spark\", \n",
    "    #     \"description\": \"Query green trip data with fare amount filter\"\n",
    "    # },\n",
    "    # {\n",
    "    #     \"code\": '''spark.sql(\"SELECT * FROM green_tripdata_2022_08 WHERE tip_amount = 10\").show()''',\n",
    "    #     \"kind\": \"spark\",\n",
    "    #     \"description\": \"Query green trip data with tip amount filter\"  \n",
    "    # },\n",
    "    {\n",
    "        \"code\": '''spark.sql(\"SELECT current_timestamp() as timestamp, 'Spark SQL works!' as message\").show()''',\n",
    "        \"kind\": \"spark\",\n",
    "        \"description\": \"Test Spark SQL with timestamp\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"üöÄ Executing Advanced Spark SQL Queries...\")\n",
    "print(\"Note: Modify table names in the code above to match your actual lakehouse tables\")\n",
    "\n",
    "# Execute advanced queries (only the ones that are not commented out)\n",
    "for i, query in enumerate(advanced_queries, 1):\n",
    "    print(f\"\\nüîÑ Executing Advanced Query {i}/{len(advanced_queries)}\")\n",
    "    result = execute_and_poll_statement(\n",
    "        query[\"code\"], \n",
    "        query[\"kind\"], \n",
    "        query[\"description\"]\n",
    "    )\n",
    "    \n",
    "    if result is None:\n",
    "        print(f\"‚ö†Ô∏è Advanced query {i} failed or timed out\")\n",
    "    \n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d2d256",
   "metadata": {},
   "source": [
    "## 11. Delete Livy Session (Cleanup)\n",
    "\n",
    "Finally, let's clean up by deleting the Livy session to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869adfe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up: Delete the Livy session\n",
    "print(\"üßπ Cleaning up: Deleting Livy session...\")\n",
    "print(f\"Session URL: {livy_base_url}/sessions/{session_id}\")\n",
    "\n",
    "delete_response = requests.delete(\n",
    "    f\"{livy_base_url}/sessions/{session_id}\",\n",
    "    headers=headers\n",
    ")\n",
    "\n",
    "if delete_response.status_code in [200, 204]:\n",
    "    print(\"‚úÖ Livy session deleted successfully!\")\n",
    "    print(\"üéâ Cleanup completed!\")\n",
    "elif delete_response.status_code == 404:\n",
    "    print(\"‚ö†Ô∏è Session already deleted or not found\")\n",
    "else:\n",
    "    print(f\"‚ùå Failed to delete session: {delete_response.status_code}\")\n",
    "    print(f\"Error: {delete_response.text}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ Livy API Test Complete!\")\n",
    "print(\"=\"*70)\n",
    "print(\"Summary of what we accomplished:\")\n",
    "print(\"‚úÖ Authenticated with Microsoft Fabric\")\n",
    "print(\"‚úÖ Created a Livy session\")\n",
    "print(\"‚úÖ Waited for session to become ready\")\n",
    "print(\"‚úÖ Executed SQL statements\")\n",
    "print(\"‚úÖ Executed Spark SQL queries\")\n",
    "print(\"‚úÖ Cleaned up the session\")\n",
    "print(\"\\nYour Livy API integration is working correctly! üöÄ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6029e321",
   "metadata": {},
   "source": [
    "## 8. Spark Application Monitoring\n",
    "\n",
    "Test the new Spark application monitoring capabilities to track the status of all Spark jobs and applications across different Fabric items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_workspace_spark_applications(workspace_id: str, continuation_token: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get all Spark applications in a workspace\n",
    "    \n",
    "    Args:\n",
    "        workspace_id: Microsoft Fabric workspace ID\n",
    "        continuation_token: Optional token for pagination\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing the API response with spark applications\n",
    "    \"\"\"\n",
    "    url = f\"{config['fabric_base_url']}/workspaces/{workspace_id}/spark/livySessions\"\n",
    "    \n",
    "    params = {}\n",
    "    if continuation_token:\n",
    "        params['continuationToken'] = continuation_token\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {auth_token}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîç Getting Spark applications from workspace: {workspace_id}\")\n",
    "        if continuation_token:\n",
    "            print(f\"üìÑ Using continuation token: {continuation_token[:20]}...\")\n",
    "            \n",
    "        response = requests.get(url, headers=headers, params=params, timeout=config['timeout_seconds'])\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"‚úÖ Successfully retrieved {len(data.get('value', []))} Spark applications\")\n",
    "            \n",
    "            # Print summary of applications\n",
    "            if data.get('value'):\n",
    "                print(\"\\nüìä Spark Applications Summary:\")\n",
    "                for i, app in enumerate(data['value'][:5], 1):  # Show first 5\n",
    "                    print(f\"   {i}. {app.get('itemName', 'N/A')} ({app.get('itemType', 'N/A')}) - State: {app.get('state', 'N/A')}\")\n",
    "                \n",
    "                if len(data['value']) > 5:\n",
    "                    print(f\"   ... and {len(data['value']) - 5} more applications\")\n",
    "                    \n",
    "                if data.get('continuationToken'):\n",
    "                    print(f\"üìÑ More data available with continuation token\")\n",
    "            else:\n",
    "                print(\"   No Spark applications found\")\n",
    "                \n",
    "            return {\n",
    "                'success': True,\n",
    "                'data': data,\n",
    "                'total_applications': len(data.get('value', [])),\n",
    "                'has_more': bool(data.get('continuationToken'))\n",
    "            }\n",
    "        else:\n",
    "            error_msg = f\"API request failed with status {response.status_code}: {response.text}\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': error_msg,\n",
    "                'status_code': response.status_code\n",
    "            }\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"Request failed: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': error_msg\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11493f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_notebook_spark_applications(workspace_id: str, notebook_id: str, continuation_token: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get all Spark applications for a specific notebook\n",
    "    \n",
    "    Args:\n",
    "        workspace_id: Microsoft Fabric workspace ID\n",
    "        notebook_id: Notebook ID\n",
    "        continuation_token: Optional token for pagination\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing the API response with spark applications\n",
    "    \"\"\"\n",
    "    url = f\"{config['fabric_base_url']}/workspaces/{workspace_id}/notebooks/{notebook_id}/livySessions\"\n",
    "    \n",
    "    params = {}\n",
    "    if continuation_token:\n",
    "        params['continuationToken'] = continuation_token\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {auth_token}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîç Getting Spark applications for notebook: {notebook_id}\")\n",
    "        if continuation_token:\n",
    "            print(f\"üìÑ Using continuation token: {continuation_token[:20]}...\")\n",
    "            \n",
    "        response = requests.get(url, headers=headers, params=params, timeout=config['timeout_seconds'])\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"‚úÖ Successfully retrieved {len(data.get('value', []))} Spark applications for notebook\")\n",
    "            \n",
    "            # Print detailed information for notebook applications\n",
    "            if data.get('value'):\n",
    "                print(\"\\nüìä Notebook Spark Applications:\")\n",
    "                for i, app in enumerate(data['value'], 1):\n",
    "                    print(f\"   {i}. Application ID: {app.get('sparkApplicationId', 'N/A')}\")\n",
    "                    print(f\"      State: {app.get('state', 'N/A')}\")\n",
    "                    print(f\"      Job Type: {app.get('jobType', 'N/A')}\")\n",
    "                    print(f\"      Submitted: {app.get('submittedDateTime', 'N/A')}\")\n",
    "                    if app.get('startDateTime'):\n",
    "                        print(f\"      Started: {app.get('startDateTime')}\")\n",
    "                    if app.get('endDateTime'):\n",
    "                        print(f\"      Ended: {app.get('endDateTime')}\")\n",
    "                    if app.get('cancellationReason'):\n",
    "                        print(f\"      Cancellation Reason: {app.get('cancellationReason')}\")\n",
    "                    print()\n",
    "                    \n",
    "                if data.get('continuationToken'):\n",
    "                    print(f\"üìÑ More data available with continuation token\")\n",
    "            else:\n",
    "                print(\"   No Spark applications found for this notebook\")\n",
    "                \n",
    "            return {\n",
    "                'success': True,\n",
    "                'data': data,\n",
    "                'total_applications': len(data.get('value', [])),\n",
    "                'has_more': bool(data.get('continuationToken'))\n",
    "            }\n",
    "        else:\n",
    "            error_msg = f\"API request failed with status {response.status_code}: {response.text}\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': error_msg,\n",
    "                'status_code': response.status_code\n",
    "            }\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"Request failed: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': error_msg\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b6f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_spark_job_definition_applications(workspace_id: str, spark_job_definition_id: str, continuation_token: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get all Spark applications for a specific Spark Job Definition\n",
    "    \n",
    "    Args:\n",
    "        workspace_id: Microsoft Fabric workspace ID\n",
    "        spark_job_definition_id: Spark Job Definition ID\n",
    "        continuation_token: Optional token for pagination\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing the API response with spark applications\n",
    "    \"\"\"\n",
    "    url = f\"{config['fabric_base_url']}/workspaces/{workspace_id}/sparkJobDefinitions/{spark_job_definition_id}/livySessions\"\n",
    "    \n",
    "    params = {}\n",
    "    if continuation_token:\n",
    "        params['continuationToken'] = continuation_token\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {auth_token}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîç Getting Spark applications for Spark Job Definition: {spark_job_definition_id}\")\n",
    "        if continuation_token:\n",
    "            print(f\"üìÑ Using continuation token: {continuation_token[:20]}...\")\n",
    "            \n",
    "        response = requests.get(url, headers=headers, params=params, timeout=config['timeout_seconds'])\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"‚úÖ Successfully retrieved {len(data.get('value', []))} Spark applications for Spark Job Definition\")\n",
    "            \n",
    "            # Print detailed information for Spark Job Definition applications\n",
    "            if data.get('value'):\n",
    "                print(\"\\nüìä Spark Job Definition Applications:\")\n",
    "                for i, app in enumerate(data['value'], 1):\n",
    "                    print(f\"   {i}. Application ID: {app.get('sparkApplicationId', 'N/A')}\")\n",
    "                    print(f\"      State: {app.get('state', 'N/A')}\")\n",
    "                    print(f\"      Job Type: {app.get('jobType', 'N/A')}\")\n",
    "                    print(f\"      Runtime Version: {app.get('runtimeVersion', 'N/A')}\")\n",
    "                    print(f\"      Submitted: {app.get('submittedDateTime', 'N/A')}\")\n",
    "                    \n",
    "                    # Show duration information\n",
    "                    if app.get('queuedDuration'):\n",
    "                        duration = app['queuedDuration']\n",
    "                        print(f\"      Queued Duration: {duration.get('value', 'N/A')} {duration.get('timeUnit', '')}\")\n",
    "                    if app.get('runningDuration'):\n",
    "                        duration = app['runningDuration']\n",
    "                        print(f\"      Running Duration: {duration.get('value', 'N/A')} {duration.get('timeUnit', '')}\")\n",
    "                    if app.get('totalDuration'):\n",
    "                        duration = app['totalDuration']\n",
    "                        print(f\"      Total Duration: {duration.get('value', 'N/A')} {duration.get('timeUnit', '')}\")\n",
    "                    \n",
    "                    if app.get('cancellationReason'):\n",
    "                        print(f\"      Cancellation Reason: {app.get('cancellationReason')}\")\n",
    "                    print()\n",
    "                    \n",
    "                if data.get('continuationToken'):\n",
    "                    print(f\"üìÑ More data available with continuation token\")\n",
    "            else:\n",
    "                print(\"   No Spark applications found for this Spark Job Definition\")\n",
    "                \n",
    "            return {\n",
    "                'success': True,\n",
    "                'data': data,\n",
    "                'total_applications': len(data.get('value', [])),\n",
    "                'has_more': bool(data.get('continuationToken'))\n",
    "            }\n",
    "        else:\n",
    "            error_msg = f\"API request failed with status {response.status_code}: {response.text}\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': error_msg,\n",
    "                'status_code': response.status_code\n",
    "            }\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"Request failed: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': error_msg\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a8cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lakehouse_spark_applications(workspace_id: str, lakehouse_id: str, continuation_token: Optional[str] = None) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Get all Spark applications for a specific lakehouse\n",
    "    \n",
    "    Args:\n",
    "        workspace_id: Microsoft Fabric workspace ID\n",
    "        lakehouse_id: Lakehouse ID\n",
    "        continuation_token: Optional token for pagination\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing the API response with spark applications\n",
    "    \"\"\"\n",
    "    url = f\"{config['fabric_base_url']}/workspaces/{workspace_id}/lakehouses/{lakehouse_id}/livySessions\"\n",
    "    \n",
    "    params = {}\n",
    "    if continuation_token:\n",
    "        params['continuationToken'] = continuation_token\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {auth_token}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        print(f\"üîç Getting Spark applications for lakehouse: {lakehouse_id}\")\n",
    "        if continuation_token:\n",
    "            print(f\"üìÑ Using continuation token: {continuation_token[:20]}...\")\n",
    "            \n",
    "        response = requests.get(url, headers=headers, params=params, timeout=config['timeout_seconds'])\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            print(f\"‚úÖ Successfully retrieved {len(data.get('value', []))} Spark applications for lakehouse\")\n",
    "            \n",
    "            # Print detailed information for lakehouse applications\n",
    "            if data.get('value'):\n",
    "                print(\"\\nüìä Lakehouse Spark Applications:\")\n",
    "                for i, app in enumerate(data['value'], 1):\n",
    "                    print(f\"   {i}. Application ID: {app.get('sparkApplicationId', 'N/A')}\")\n",
    "                    print(f\"      Livy ID: {app.get('livyId', 'N/A')}\")\n",
    "                    print(f\"      State: {app.get('state', 'N/A')}\")\n",
    "                    print(f\"      Origin: {app.get('origin', 'N/A')}\")\n",
    "                    print(f\"      Operation: {app.get('operationName', 'N/A')}\")\n",
    "                    \n",
    "                    # Show submitter information\n",
    "                    if app.get('submitter'):\n",
    "                        submitter = app['submitter']\n",
    "                        print(f\"      Submitted by: {submitter.get('type', 'N/A')} ({submitter.get('id', 'N/A')[:8]}...)\")\n",
    "                    \n",
    "                    if app.get('capacityId'):\n",
    "                        print(f\"      Capacity ID: {app.get('capacityId')[:8]}...\")\n",
    "                    \n",
    "                    if app.get('cancellationReason'):\n",
    "                        print(f\"      Cancellation Reason: {app.get('cancellationReason')}\")\n",
    "                    print()\n",
    "                    \n",
    "                if data.get('continuationToken'):\n",
    "                    print(f\"üìÑ More data available with continuation token\")\n",
    "            else:\n",
    "                print(\"   No Spark applications found for this lakehouse\")\n",
    "                \n",
    "            return {\n",
    "                'success': True,\n",
    "                'data': data,\n",
    "                'total_applications': len(data.get('value', [])),\n",
    "                'has_more': bool(data.get('continuationToken'))\n",
    "            }\n",
    "        else:\n",
    "            error_msg = f\"API request failed with status {response.status_code}: {response.text}\"\n",
    "            print(f\"‚ùå {error_msg}\")\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': error_msg,\n",
    "                'status_code': response.status_code\n",
    "            }\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        error_msg = f\"Request failed: {str(e)}\"\n",
    "        print(f\"‚ùå {error_msg}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'error': error_msg\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3338c924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the Spark Application Monitoring APIs\n",
    "print(\"üöÄ Testing Spark Application Monitoring APIs\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Your specific IDs for testing\n",
    "notebook_id = \"8809828e-7212-43fa-8463-8de8b3873288\"\n",
    "spark_job_definition_id = \"d410b138-5c4f-42af-b1ed-4430138c7b79\"\n",
    "\n",
    "print(f\"Using your configuration:\")\n",
    "print(f\"  Workspace ID: {config['workspace_id']}\")\n",
    "print(f\"  Lakehouse ID: {config['lakehouse_id']}\")\n",
    "print(f\"  Notebook ID: {notebook_id}\")\n",
    "print(f\"  Spark Job Definition ID: {spark_job_definition_id}\")\n",
    "print()\n",
    "\n",
    "# Test 1: Get all Spark applications in the workspace\n",
    "print(\"üìã Test 1: Get all Spark applications in workspace\")\n",
    "workspace_result = get_workspace_spark_applications(config['workspace_id'])\n",
    "\n",
    "if workspace_result['success']:\n",
    "    print(f\"‚úÖ Found {workspace_result['total_applications']} applications in workspace\")\n",
    "    if workspace_result['has_more']:\n",
    "        print(\"üìÑ There are more applications available (pagination needed)\")\n",
    "else:\n",
    "    print(f\"‚ùå Failed to get workspace applications: {workspace_result.get('error', 'Unknown error')}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "\n",
    "# Test 2: Get Spark applications for the specific notebook\n",
    "print(\"üìî Test 2: Get Spark applications for notebook\")\n",
    "notebook_result = get_notebook_spark_applications(config['workspace_id'], notebook_id)\n",
    "\n",
    "if notebook_result['success']:\n",
    "    print(f\"‚úÖ Found {notebook_result['total_applications']} applications for notebook\")\n",
    "    if notebook_result['has_more']:\n",
    "        print(\"üìÑ There are more applications available (pagination needed)\")\n",
    "else:\n",
    "    print(f\"‚ùå Failed to get notebook applications: {notebook_result.get('error', 'Unknown error')}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "\n",
    "# Test 3: Get Spark applications for the lakehouse\n",
    "print(\"üè† Test 3: Get Spark applications for lakehouse\")\n",
    "lakehouse_result = get_lakehouse_spark_applications(config['workspace_id'], config['lakehouse_id'])\n",
    "\n",
    "if lakehouse_result['success']:\n",
    "    print(f\"‚úÖ Found {lakehouse_result['total_applications']} applications for lakehouse\")\n",
    "    if lakehouse_result['has_more']:\n",
    "        print(\"üìÑ There are more applications available (pagination needed)\")\n",
    "else:\n",
    "    print(f\"‚ùå Failed to get lakehouse applications: {lakehouse_result.get('error', 'Unknown error')}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 40 + \"\\n\")\n",
    "\n",
    "# Test 4: Get Spark applications for the Spark Job Definition\n",
    "print(\"‚öôÔ∏è Test 4: Get Spark applications for Spark Job Definition\")\n",
    "sjd_result = get_spark_job_definition_applications(config['workspace_id'], spark_job_definition_id)\n",
    "\n",
    "if sjd_result['success']:\n",
    "    print(f\"‚úÖ Found {sjd_result['total_applications']} applications for Spark Job Definition\")\n",
    "    if sjd_result['has_more']:\n",
    "        print(\"üìÑ There are more applications available (pagination needed)\")\n",
    "else:\n",
    "    print(f\"‚ùå Failed to get Spark Job Definition applications: {sjd_result.get('error', 'Unknown error')}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéØ Spark Application Monitoring Test Summary:\")\n",
    "print(f\"  Workspace Applications: {'‚úÖ' if workspace_result['success'] else '‚ùå'} ({workspace_result.get('total_applications', 0)} found)\")\n",
    "print(f\"  Notebook Applications: {'‚úÖ' if notebook_result['success'] else '‚ùå'} ({notebook_result.get('total_applications', 0)} found)\")\n",
    "print(f\"  Lakehouse Applications: {'‚úÖ' if lakehouse_result['success'] else '‚ùå'} ({lakehouse_result.get('total_applications', 0)} found)\")\n",
    "print(f\"  Spark Job Def Applications: {'‚úÖ' if sjd_result['success'] else '‚ùå'} ({sjd_result.get('total_applications', 0)} found)\")\n",
    "\n",
    "# Store results for further analysis\n",
    "monitoring_results = {\n",
    "    'workspace': workspace_result,\n",
    "    'notebook': notebook_result,\n",
    "    'lakehouse': lakehouse_result,\n",
    "    'spark_job_definition': sjd_result\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0d937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Analysis: Filter and analyze the monitoring results\n",
    "print(\"üîç Advanced Analysis: Filtering and Analyzing Spark Applications\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def analyze_spark_applications(results_dict: Dict[str, Dict[str, Any]]) -> None:\n",
    "    \"\"\"Analyze Spark applications across different sources\"\"\"\n",
    "    \n",
    "    all_applications = []\n",
    "    \n",
    "    # Collect all applications from different sources\n",
    "    for source, result in results_dict.items():\n",
    "        if result.get('success') and result.get('data', {}).get('value'):\n",
    "            for app in result['data']['value']:\n",
    "                app['source'] = source\n",
    "                all_applications.append(app)\n",
    "    \n",
    "    if not all_applications:\n",
    "        print(\"‚ùå No applications found across all sources\")\n",
    "        return\n",
    "    \n",
    "    print(f\"üìä Total applications found: {len(all_applications)}\")\n",
    "    print()\n",
    "    \n",
    "    # Analyze by state\n",
    "    states = {}\n",
    "    for app in all_applications:\n",
    "        state = app.get('state', 'Unknown')\n",
    "        states[state] = states.get(state, 0) + 1\n",
    "    \n",
    "    print(\"üìà Applications by State:\")\n",
    "    for state, count in sorted(states.items()):\n",
    "        print(f\"  {state}: {count}\")\n",
    "    print()\n",
    "    \n",
    "    # Analyze by item type\n",
    "    item_types = {}\n",
    "    for app in all_applications:\n",
    "        item_type = app.get('itemType', 'Unknown')\n",
    "        item_types[item_type] = item_types.get(item_type, 0) + 1\n",
    "    \n",
    "    print(\"üìà Applications by Item Type:\")\n",
    "    for item_type, count in sorted(item_types.items()):\n",
    "        print(f\"  {item_type}: {count}\")\n",
    "    print()\n",
    "    \n",
    "    # Analyze by job type\n",
    "    job_types = {}\n",
    "    for app in all_applications:\n",
    "        job_type = app.get('jobType', 'Unknown')\n",
    "        job_types[job_type] = job_types.get(job_type, 0) + 1\n",
    "    \n",
    "    print(\"üìà Applications by Job Type:\")\n",
    "    for job_type, count in sorted(job_types.items()):\n",
    "        print(f\"  {job_type}: {count}\")\n",
    "    print()\n",
    "    \n",
    "    # Find recent applications (last 24 hours)\n",
    "    from datetime import datetime, timedelta\n",
    "    recent_apps = []\n",
    "    now = datetime.utcnow()\n",
    "    \n",
    "    for app in all_applications:\n",
    "        submitted_str = app.get('submittedDateTime')\n",
    "        if submitted_str:\n",
    "            try:\n",
    "                # Parse the datetime string (ISO format)\n",
    "                submitted_dt = datetime.fromisoformat(submitted_str.replace('Z', '+00:00'))\n",
    "                if (now - submitted_dt.replace(tzinfo=None)) <= timedelta(hours=24):\n",
    "                    recent_apps.append(app)\n",
    "            except ValueError:\n",
    "                pass  # Skip invalid datetime formats\n",
    "    \n",
    "    print(f\"üïê Recent Applications (last 24 hours): {len(recent_apps)}\")\n",
    "    if recent_apps:\n",
    "        for i, app in enumerate(recent_apps[:5], 1):  # Show first 5\n",
    "            print(f\"  {i}. {app.get('itemName', 'N/A')} ({app.get('state', 'N/A')}) - {app.get('submittedDateTime', 'N/A')}\")\n",
    "        if len(recent_apps) > 5:\n",
    "            print(f\"  ... and {len(recent_apps) - 5} more recent applications\")\n",
    "    print()\n",
    "    \n",
    "    # Find failed/cancelled applications\n",
    "    failed_apps = [app for app in all_applications if app.get('state') in ['Failed', 'Cancelled', 'Error']]\n",
    "    print(f\"‚ùå Failed/Cancelled Applications: {len(failed_apps)}\")\n",
    "    if failed_apps:\n",
    "        for i, app in enumerate(failed_apps[:3], 1):  # Show first 3\n",
    "            print(f\"  {i}. {app.get('itemName', 'N/A')} ({app.get('state', 'N/A')})\")\n",
    "            if app.get('cancellationReason'):\n",
    "                print(f\"     Reason: {app.get('cancellationReason')}\")\n",
    "        if len(failed_apps) > 3:\n",
    "            print(f\"  ... and {len(failed_apps) - 3} more failed applications\")\n",
    "    print()\n",
    "    \n",
    "    # Runtime version analysis\n",
    "    runtime_versions = {}\n",
    "    for app in all_applications:\n",
    "        version = app.get('runtimeVersion', 'Unknown')\n",
    "        runtime_versions[version] = runtime_versions.get(version, 0) + 1\n",
    "    \n",
    "    print(\"üìà Applications by Runtime Version:\")\n",
    "    for version, count in sorted(runtime_versions.items()):\n",
    "        print(f\"  {version}: {count}\")\n",
    "\n",
    "# Run the analysis\n",
    "if any(result.get('success') for result in monitoring_results.values()):\n",
    "    analyze_spark_applications(monitoring_results)\n",
    "else:\n",
    "    print(\"‚ùå No successful monitoring results to analyze\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516b55d0",
   "metadata": {},
   "source": [
    "## 9. MCP Server Testing\n",
    "\n",
    "Test the MCP server tools for Spark application monitoring. This section shows how to interact with the MCP server that exposes these monitoring capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f5c2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example MCP Server Tool Calls\n",
    "print(\"ü§ñ MCP Server Tool Examples\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"The following are example queries you can use with Claude Desktop\")\n",
    "print(\"when the MCP server is running:\\n\")\n",
    "\n",
    "# Example tool calls for the MCP server\n",
    "example_queries = [\n",
    "    {\n",
    "        \"title\": \"Get all Spark applications in workspace\",\n",
    "        \"query\": f\"Get all Spark applications in workspace {config['workspace_id']}\",\n",
    "        \"tool\": \"get-workspace-spark-applications\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Get Spark applications for specific notebook\",\n",
    "        \"query\": f\"Get Spark applications for notebook {notebook_id} in workspace {config['workspace_id']}\",\n",
    "        \"tool\": \"get-notebook-spark-applications\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Get Spark applications for lakehouse\",\n",
    "        \"query\": f\"Get Spark applications for lakehouse {config['lakehouse_id']} in workspace {config['workspace_id']}\",\n",
    "        \"tool\": \"get-lakehouse-spark-applications\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Get Spark applications for Spark Job Definition\",\n",
    "        \"query\": f\"Get Spark applications for Spark Job Definition {spark_job_definition_id} in workspace {config['workspace_id']}\",\n",
    "        \"tool\": \"get-spark-job-definition-applications\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Generate Spark monitoring dashboard\",\n",
    "        \"query\": f\"Generate a comprehensive Spark monitoring dashboard for workspace {config['workspace_id']}\",\n",
    "        \"tool\": \"get-spark-monitoring-dashboard\"\n",
    "    }\n",
    "]\n",
    "\n",
    "for i, example in enumerate(example_queries, 1):\n",
    "    print(f\"{i}. {example['title']}\")\n",
    "    print(f\"   Claude Query: \\\"{example['query']}\\\"\")\n",
    "    print(f\"   MCP Tool: {example['tool']}\")\n",
    "    print()\n",
    "\n",
    "print(\"üîß MCP Server Tool Parameters:\")\n",
    "print(\"\"\"\n",
    "Available MCP tools for Spark monitoring:\n",
    "- get-workspace-spark-applications\n",
    "  Parameters: bearerToken, workspaceId, continuationToken (optional)\n",
    "\n",
    "- get-notebook-spark-applications  \n",
    "  Parameters: bearerToken, workspaceId, notebookId, continuationToken (optional)\n",
    "\n",
    "- get-lakehouse-spark-applications\n",
    "  Parameters: bearerToken, workspaceId, lakehouseId, continuationToken (optional)\n",
    "\n",
    "- get-spark-job-definition-applications\n",
    "  Parameters: bearerToken, workspaceId, sparkJobDefinitionId, continuationToken (optional)\n",
    "\n",
    "- get-spark-application-details\n",
    "  Parameters: bearerToken, workspaceId, livyId\n",
    "\n",
    "- cancel-spark-application\n",
    "  Parameters: bearerToken, workspaceId, livyId\n",
    "\n",
    "- get-spark-monitoring-dashboard\n",
    "  Parameters: bearerToken, workspaceId\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nüìã To use these tools with Claude Desktop:\")\n",
    "print(\"1. Make sure your MCP server is running (npm start)\")\n",
    "print(\"2. Configure Claude Desktop with the server in claude_desktop_config.json\")\n",
    "print(\"3. Ask Claude to use these monitoring capabilities\")\n",
    "print(\"4. Claude will automatically call the appropriate MCP tools\")\n",
    "\n",
    "# Show configuration for Claude Desktop\n",
    "print(\"\\n‚öôÔ∏è Claude Desktop Configuration:\")\n",
    "print(\"\"\"\n",
    "Add this to your claude_desktop_config.json:\n",
    "\n",
    "{\n",
    "  \"mcpServers\": {\n",
    "    \"fabric-analytics\": {\n",
    "      \"command\": \"node\",\n",
    "      \"args\": [\"C:\\\\\\\\FULL\\\\\\\\PATH\\\\\\\\TO\\\\\\\\YOUR\\\\\\\\PROJECT\\\\\\\\build\\\\\\\\index.js\"]\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
